# Daily Movie Scraper - Parallel Edition
name: Daily Scrape

on:
  schedule:
    - cron: '0 23 * * *'  # 6 AM WIB
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        batch: [0, 1, 2, 3, 4, 5, 6, 7, 8]

    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          uv sync
          uv run playwright install chromium
          uv run playwright install-deps chromium

      - name: Run scraper batch ${{ matrix.batch }}
        run: uv run python -m backend.cli --schedules --batch ${{ matrix.batch }} --total-batches 9

      - name: Upload batch artifact
        uses: actions/upload-artifact@v4
        with:
          name: batch-${{ matrix.batch }}
          path: data/batch_*.json
          retention-days: 1

  merge:
    needs: scrape
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: uv sync

      - name: Download all batch artifacts
        uses: actions/download-artifact@v4
        with:
          path: data/
          pattern: batch-*
          merge-multiple: true

      - name: Merge batches
        run: uv run python -m backend.cli.merge_batches

      - name: Validate merged data
        run: uv run python -m backend.cli.validate

      - name: Upload to Firestore
        run: uv run python -m backend.cli.populate_firestore
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}

      - name: Upload per-movie schedules
        run: uv run python -m backend.cli.upload_schedules
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}

      - name: Upload final artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-data-${{ github.run_id }}
          path: data/movies_*.json
          retention-days: 7

  # Ensure valid token before parallel seat scrape jobs
  token-refresh-pre-seat:
    needs: merge
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: uv sync

      - name: Refresh token via API
        run: |
          uv run python -c "
          import asyncio
          from backend.infrastructure.token_refresher import TokenRefresher

          async def refresh():
              refresher = TokenRefresher()
              token = await refresher.ensure_valid_token()
              print(f'âœ… Token valid: {token.minutes_until_expiry} min remaining')

          asyncio.run(refresh())
          "
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}

  seat-morning-scrape:
    needs: token-refresh-pre-seat
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        batch: [0, 1, 2, 3, 4, 5, 6, 7, 8]

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
          fetch-depth: 0

      - uses: astral-sh/setup-uv@v5

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          uv sync
          uv run playwright install chromium
          uv run playwright install-deps chromium

      - name: Download movie data artifact
        uses: actions/download-artifact@v4
        with:
          name: scrape-data-${{ github.run_id }}
          path: data/
          merge-multiple: true

      - name: Debug data directory
        run: ls -la data/

      # Token already refreshed by token-refresh-pre-seat job

      - name: Run morning seat scraper batch ${{ matrix.batch }}
        run: uv run python -m backend.cli.cli seats --mode morning --batch ${{ matrix.batch }} --total-batches 9
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}

      - name: Upload seat batch artifact
        uses: actions/upload-artifact@v4
        with:
          name: seat-batch-${{ matrix.batch }}
          path: data/seats_morning_*.json
          retention-days: 1

  seat-merge-upload:
    needs: seat-morning-scrape
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: uv sync

      - name: Download all seat batch artifacts
        uses: actions/download-artifact@v4
        with:
          path: data/
          pattern: seat-batch-*
          merge-multiple: true

      - name: Merge and upload seat data
        run: uv run python -m backend.cli.upload_seats
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}

      - name: Upload final seat artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: seats-morning-${{ github.run_id }}
          path: data/seats_morning_*.json
          retention-days: 7
