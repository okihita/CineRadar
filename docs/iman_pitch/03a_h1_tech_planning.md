# ðŸ”§ H1 2026 Technical Planning
## CineRadar AdTech Platform (January - June)

---

## Executive Summary

This document outlines the technical implementation plan for H1 2026, focused on building the CineRadar AdTech platform - transforming cinema occupancy data into advertising inventory and studio analytics products.

### Technology Stack (Latest Stable - 2026)

| Layer | Technology | Version | Purpose |
|-------|------------|---------|---------|
| **Runtime** | Node.js | 24 LTS | API servers, real-time services |
| **Language** | TypeScript | 5.6+ | Type safety across all JS/TS |
| **Python** | Python | 3.14 | ML/AI, data processing |
| **Frontend** | Next.js | 16.x | Web applications |
| **React** | React | 19.x | UI components |
| **Database** | PostgreSQL | 17 | Primary data store |
| **Time-Series** | TimescaleDB | 2.x | Occupancy time-series data |
| **Cache** | Redis | 8.x | Caching, real-time pub/sub |
| **Queue** | BullMQ | 5.x | Job queue (Redis-based) |
| **Cloud** | GCP/AWS | - | Infrastructure |

---

# JANUARY (Weeks 1-4)
## Foundation: Real-Time Data Infrastructure

---

### Week 1: Real-Time Occupancy API

**Objective:** Transform 15-minute scraper data into real-time API for advertisers.

#### Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CineRadar Data Pipeline               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Scraper    â”‚â”€â”€â”€â–¶â”‚  PostgreSQL â”‚â”€â”€â”€â–¶â”‚   Redis     â”‚ â”‚
â”‚  â”‚  (15 min)   â”‚    â”‚  TimescaleDBâ”‚    â”‚   Cache     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                   â”‚        â”‚
â”‚                            â–¼                   â–¼        â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚                     â”‚       API Gateway (Hono.js)     â”‚â”‚
â”‚                     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚                     â”‚ GET /v1/occupancy/:theatreId    â”‚â”‚
â”‚                     â”‚ GET /v1/occupancy/live          â”‚â”‚
â”‚                     â”‚ WS  /v1/occupancy/stream        â”‚â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tech Stack Details

| Component | Technology | Rationale |
|-----------|------------|-----------|
| API Framework | **Hono.js** (Node.js 24) | Lightweight, edge-ready, TypeScript-native |
| WebSocket | **ws** + **socket.io** | Real-time streaming to clients |
| Database | **PostgreSQL 17 + TimescaleDB** | Time-series optimized for occupancy data |
| Cache | **Redis 8** | Sub-millisecond response times |
| Rate Limiting | **@hono/rate-limiter** | Protect API from abuse |
| Auth | **JWT (jose)** | Stateless authentication |

#### Database Schema

```sql
-- TimescaleDB hypertable for occupancy data
CREATE TABLE occupancy_readings (
    time TIMESTAMPTZ NOT NULL,
    theatre_id UUID NOT NULL,
    movie_id UUID,
    showtime_id UUID,
    total_seats INTEGER,
    occupied_seats INTEGER,
    occupancy_rate DECIMAL(5,2),
    PRIMARY KEY (time, theatre_id)
);

-- Convert to hypertable (TimescaleDB)
SELECT create_hypertable('occupancy_readings', 'time');

-- Continuous aggregate for hourly summaries
CREATE MATERIALIZED VIEW occupancy_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    theatre_id,
    AVG(occupancy_rate) AS avg_occupancy,
    MAX(occupancy_rate) AS peak_occupancy,
    COUNT(*) AS sample_count
FROM occupancy_readings
GROUP BY bucket, theatre_id;
```

#### API Endpoints

```typescript
// Hono.js API routes (TypeScript)
import { Hono } from 'hono';
import { jwt } from 'hono/jwt';
import { rateLimiter } from '@hono/rate-limiter';

const app = new Hono();

// Middleware
app.use('/v1/*', jwt({ secret: process.env.JWT_SECRET }));
app.use('/v1/*', rateLimiter({ limit: 1000, window: '1h' }));

// GET /v1/occupancy/:theatreId
app.get('/v1/occupancy/:theatreId', async (c) => {
    const { theatreId } = c.req.param();
    const data = await redis.get(`occupancy:${theatreId}`);
    return c.json(data);
});

// GET /v1/occupancy/live - All theatres, last reading
app.get('/v1/occupancy/live', async (c) => {
    const data = await getLatestReadings();
    return c.json({ readings: data, timestamp: new Date().toISOString() });
});
```

#### Deliverables

- [ ] Extend scraper to 15-min intervals with JIT seat checking
- [ ] Create PostgreSQL schema with TimescaleDB partitioning
- [ ] Build Hono.js REST API with Swagger/OpenAPI docs
- [ ] Implement WebSocket streaming for real-time updates
- [ ] Deploy to GCP Cloud Run with auto-scaling
- [ ] Set up monitoring (Grafana Cloud + Prometheus)

---

### Week 2: Predictive Demand Model v1

**Objective:** Predict seat occupancy 24-72 hours ahead to enable premium ad pricing.

#### ML Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Demand Prediction Pipeline                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Feature    â”‚â”€â”€â”€â–¶â”‚  XGBoost    â”‚â”€â”€â”€â–¶â”‚  FastAPI    â”‚ â”‚
â”‚  â”‚  Store      â”‚    â”‚  Model      â”‚    â”‚  Serving    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                   â”‚        â”‚
â”‚         â–¼                  â–¼                   â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DuckDB     â”‚    â”‚  MLflow     â”‚    â”‚  Redis      â”‚ â”‚
â”‚  â”‚  (local)    â”‚    â”‚  (tracking) â”‚    â”‚  (cache)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tech Stack Details

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| Language | Python | 3.14 | ML development |
| ML Framework | XGBoost | 2.1+ | Gradient boosting model |
| Feature Engineering | Polars | 1.x | Fast DataFrame processing |
| API Serving | FastAPI | 0.115+ | Model inference API |
| Experiment Tracking | MLflow | 2.x | Model versioning |
| Local Dev | DuckDB | 1.x | Fast local analytics |

#### Feature Engineering

```python
# features.py - Polars for fast feature engineering
import polars as pl
from datetime import datetime, timedelta

def build_features(df: pl.DataFrame) -> pl.DataFrame:
    return df.with_columns([
        # Temporal features
        pl.col("showtime").dt.weekday().alias("day_of_week"),
        pl.col("showtime").dt.hour().alias("hour"),
        pl.lit(is_holiday(pl.col("showtime"))).alias("is_holiday"),
        
        # Movie features
        pl.col("movie_age_days").log1p().alias("movie_age_log"),
        pl.col("tmdb_popularity").rank().over("date").alias("popularity_rank"),
        
        # Theatre features
        pl.col("theatre_heat_score").alias("heat_score"),
        pl.col("avg_occupancy_7d").alias("theatre_momentum"),
        
        # Cyclical encoding for time
        (2 * 3.14159 * pl.col("hour") / 24).sin().alias("hour_sin"),
        (2 * 3.14159 * pl.col("hour") / 24).cos().alias("hour_cos"),
    ])
```

#### Model Training

```python
# train.py - XGBoost with MLflow tracking
import xgboost as xgb
import mlflow
from sklearn.metrics import mean_absolute_error

def train_model(X_train, y_train, X_val, y_val):
    mlflow.set_experiment("demand_prediction")
    
    with mlflow.start_run():
        params = {
            "objective": "reg:squarederror",
            "max_depth": 6,
            "learning_rate": 0.1,
            "n_estimators": 200,
            "early_stopping_rounds": 20,
        }
        
        model = xgb.XGBRegressor(**params)
        model.fit(X_train, y_train, eval_set=[(X_val, y_val)])
        
        # Log metrics
        preds = model.predict(X_val)
        mae = mean_absolute_error(y_val, preds)
        mlflow.log_metric("mae", mae)
        mlflow.log_params(params)
        mlflow.xgboost.log_model(model, "model")
        
        return model, mae
```

#### FastAPI Inference Service

```python
# serve.py - FastAPI model serving
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import xgboost as xgb

app = FastAPI(title="CineRadar Demand Prediction API")

class PredictionRequest(BaseModel):
    theatre_id: str
    movie_id: str
    showtime: str  # ISO format
    
class PredictionResponse(BaseModel):
    predicted_occupancy: float
    confidence_interval: tuple[float, float]
    features_used: dict

@app.post("/predict", response_model=PredictionResponse)
async def predict_demand(request: PredictionRequest):
    features = await build_features_for_prediction(request)
    prediction = model.predict(features)[0]
    
    return PredictionResponse(
        predicted_occupancy=round(prediction, 2),
        confidence_interval=(prediction * 0.85, prediction * 1.15),
        features_used=features.to_dict()
    )
```

#### Deliverables

- [ ] ETL pipeline for historical occupancy (6 months)
- [ ] Feature engineering with Polars (15+ features)
- [ ] Train XGBoost model (target: MAE < 12%)
- [ ] FastAPI prediction endpoint with caching
- [ ] MLflow experiment tracking
- [ ] Streamlit internal dashboard for model monitoring

---

### Week 3: Theatre Heat Score System

**Objective:** Rank theatres by commercial value for advertisers.

#### Scoring Algorithm

```python
# heat_score.py - Theatre ranking algorithm
from dataclasses import dataclass
import numpy as np

@dataclass
class TheatreMetrics:
    occupancy_rate: float      # 0-100
    revenue_index: float       # Relative to average
    concession_rate: float     # Concession per ticket
    growth_rate: float         # Week-over-week change
    consistency: float         # Variance in occupancy

def calculate_heat_score(metrics: TheatreMetrics) -> float:
    """
    Calculate theatre heat score (0-100)
    
    Weights:
    - Occupancy (30%): Higher is better
    - Revenue (25%): Higher revenue = premium location
    - Concession (20%): Higher attach rate = engaged audience
    - Growth (15%): Positive momentum is valuable
    - Consistency (10%): Predictable is better for advertisers
    """
    
    # Normalize each metric to 0-100 scale
    norm_occupancy = min(metrics.occupancy_rate, 100)
    norm_revenue = min(metrics.revenue_index * 50, 100)
    norm_concession = min(metrics.concession_rate * 100, 100)
    norm_growth = 50 + (metrics.growth_rate * 100)  # -50% to +50% â†’ 0-100
    norm_consistency = max(0, 100 - metrics.consistency * 2)  # Lower variance = higher score
    
    heat_score = (
        0.30 * norm_occupancy +
        0.25 * norm_revenue +
        0.20 * norm_concession +
        0.15 * norm_growth +
        0.10 * norm_consistency
    )
    
    return round(np.clip(heat_score, 0, 100), 1)
```

#### Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Backend | Node.js 24 + Hono.js | API serving |
| Frontend | Next.js 16 + React 19 | Dashboard |
| Visualization | Recharts + D3.js | Charts and maps |
| Database | PostgreSQL 17 | Storage |
| Export | React-PDF + xlsx | Reports |

#### Deliverables

- [ ] Define scoring formula with stakeholders
- [ ] Build daily calculation pipeline (BullMQ jobs)
- [ ] Create leaderboard dashboard UI
- [ ] Drill-down analytics per theatre
- [ ] PDF/Excel export for sales team

---

### Week 4: Developer Platform Launch

**Objective:** Enable third-party developers to build on CineRadar data.

#### Platform Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Developer Platform                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Portal     â”‚    â”‚  API Keys   â”‚    â”‚  SDKs       â”‚ â”‚
â”‚  â”‚  (Next.js)  â”‚    â”‚  (Postgres) â”‚    â”‚  (TS/Python)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                   â”‚        â”‚
â”‚         â–¼                  â–¼                   â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚          API Gateway with Usage Tracking           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Billing    â”‚    â”‚  Analytics  â”‚    â”‚  Docs       â”‚ â”‚
â”‚  â”‚  (Stripe)   â”‚    â”‚  (PostHog)  â”‚    â”‚  (Mintlify) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### SDKs

```typescript
// TypeScript SDK (@cineradar/sdk)
import { CineRadar } from '@cineradar/sdk';

const client = new CineRadar({ 
    apiKey: 'cr_live_xxx',
    environment: 'production'  // or 'sandbox'
});

// Get real-time occupancy
const occupancy = await client.occupancy.get('theatre_123');

// Get predictions
const prediction = await client.predictions.demand({
    theatreId: 'theatre_123',
    movieId: 'movie_456',
    showtime: '2026-01-15T19:00:00+07:00'
});

// Stream live updates
client.occupancy.stream('theatre_123', (data) => {
    console.log('New reading:', data);
});
```

```python
# Python SDK (cineradar)
from cineradar import CineRadar

client = CineRadar(api_key="cr_live_xxx")

# Get occupancy
occupancy = client.occupancy.get("theatre_123")

# Get predictions  
prediction = client.predictions.demand(
    theatre_id="theatre_123",
    movie_id="movie_456",
    showtime="2026-01-15T19:00:00+07:00"
)

# Batch operations
theatres = client.theatres.list(city="JAKARTA", chain="XXI")
```

#### Deliverables

- [ ] Developer portal (Next.js 16)
- [ ] API key management with scopes
- [ ] TypeScript SDK (npm: @cineradar/sdk)
- [ ] Python SDK (PyPI: cineradar)
- [ ] Usage dashboard with billing (Stripe)
- [ ] Interactive API docs (Mintlify)

---

# FEBRUARY (Weeks 5-8)
## AdTech: Billboard Inventory System

---

### Week 5: Billboard Inventory Database

**Objective:** Map all cinema billboard/DOOH inventory across Indonesia.

#### Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Scraping | Playwright + Crawlee | JS-rendered pages |
| Geocoding | Google Maps Places API | Location data |
| Database | PostGIS (PostgreSQL 17) | Spatial queries |
| Visualization | Mapbox GL JS v3 | Interactive maps |

#### Database Schema

```sql
-- PostGIS extension
CREATE EXTENSION IF NOT EXISTS postgis;

-- Billboard inventory table
CREATE TABLE billboards (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    theatre_id UUID REFERENCES theatres(id),
    
    -- Location
    location GEOGRAPHY(POINT, 4326) NOT NULL,
    address TEXT,
    floor_level VARCHAR(20),  -- 'ground', 'lobby', 'entrance'
    
    -- Physical specs
    size_sqm DECIMAL(6,2),
    width_cm INTEGER,
    height_cm INTEGER,
    orientation VARCHAR(20),  -- 'portrait', 'landscape'
    type VARCHAR(30),         -- 'static', 'digital', 'led'
    
    -- Valuation
    estimated_daily_impressions INTEGER,
    current_cpm_idr DECIMAL(12,2),
    premium_multiplier DECIMAL(3,2) DEFAULT 1.0,
    
    -- Media
    photos JSONB,  -- [{url, caption, taken_at}]
    
    -- Metadata
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Spatial index
CREATE INDEX billboards_location_idx ON billboards USING GIST (location);

-- Find billboards within radius
CREATE OR REPLACE FUNCTION find_billboards_nearby(
    lat DOUBLE PRECISION,
    lng DOUBLE PRECISION,
    radius_km DOUBLE PRECISION
) RETURNS TABLE (
    billboard_id UUID,
    distance_km DOUBLE PRECISION,
    theatre_name TEXT
) AS $$
    SELECT 
        b.id,
        ST_Distance(b.location, ST_Point(lng, lat)::geography) / 1000 AS distance_km,
        t.name
    FROM billboards b
    JOIN theatres t ON b.theatre_id = t.theatre_id
    WHERE ST_DWithin(b.location, ST_Point(lng, lat)::geography, radius_km * 1000)
    ORDER BY distance_km;
$$ LANGUAGE SQL;
```

#### Deliverables

- [ ] Scrape all cinema billboard locations (500+ venues)
- [ ] Geocode with Google Places API
- [ ] Build PostGIS database with spatial queries
- [ ] Create Mapbox visualization with filters
- [ ] Impression estimation model (foot traffic Ã— visibility)

---

### Week 6: Dynamic CPM Calculator

**Objective:** Real-time pricing based on occupancy and demand.

#### Pricing Engine

```typescript
// pricing.ts - Dynamic CPM calculation
interface PricingContext {
    basePrice: number;        // Base CPM in IDR
    occupancy: number;        // Current occupancy 0-100
    avgOccupancy: number;     // Theatre average
    hour: number;             // 0-23
    dayOfWeek: number;        // 0-6
    isHoliday: boolean;
    isBlockbuster: boolean;   // Premiere or major release
}

// Time-based multipliers
const HOUR_MULTIPLIERS: Record<number, number> = {
    9: 0.7, 10: 0.8, 11: 0.85, 12: 0.9,   // Morning
    13: 0.95, 14: 1.0, 15: 1.0, 16: 1.0,  // Afternoon
    17: 1.1, 18: 1.2, 19: 1.3, 20: 1.4,   // Prime time
    21: 1.35, 22: 1.25, 23: 1.1           // Late night
};

const DAY_MULTIPLIERS: Record<number, number> = {
    0: 1.3,  // Sunday
    1: 0.8,  // Monday
    2: 0.85, // Tuesday
    3: 0.85, // Wednesday
    4: 0.9,  // Thursday
    5: 1.2,  // Friday
    6: 1.4   // Saturday
};

function calculateDynamicCPM(ctx: PricingContext): number {
    // Base multipliers
    const occupancyMultiplier = Math.max(0.5, ctx.occupancy / ctx.avgOccupancy);
    const timeMultiplier = HOUR_MULTIPLIERS[ctx.hour] ?? 1.0;
    const dayMultiplier = DAY_MULTIPLIERS[ctx.dayOfWeek] ?? 1.0;
    const holidayMultiplier = ctx.isHoliday ? 1.5 : 1.0;
    const eventMultiplier = ctx.isBlockbuster ? 2.0 : 1.0;
    
    const dynamicCPM = ctx.basePrice 
        * occupancyMultiplier 
        * timeMultiplier 
        * dayMultiplier 
        * holidayMultiplier 
        * eventMultiplier;
    
    // Round to nearest 500 IDR
    return Math.round(dynamicCPM / 500) * 500;
}
```

#### Deliverables

- [ ] Define pricing algorithm with stakeholders
- [ ] Build pricing API with Redis cache (1-min TTL)
- [ ] Create price trend visualizations
- [ ] A/B testing framework
- [ ] Admin override interface

---

### Week 7: DOOH Integration API

**Objective:** Connect to programmatic DOOH networks.

#### OpenRTB 2.6 Implementation

```rust
// Rust bid server for high-performance OpenRTB
// Cargo.toml dependencies: axum, tokio, serde, openrtb

use axum::{routing::post, Json, Router};
use serde::{Deserialize, Serialize};

#[derive(Deserialize)]
struct BidRequest {
    id: String,
    imp: Vec<Impression>,
    device: Device,
    app: Option<App>,
}

#[derive(Serialize)]
struct BidResponse {
    id: String,
    seatbid: Vec<SeatBid>,
}

async fn handle_bid(Json(req): Json<BidRequest>) -> Json<BidResponse> {
    // Process bid in <10ms
    let bid = calculate_bid(&req).await;
    
    Json(BidResponse {
        id: req.id,
        seatbid: vec![SeatBid {
            bid: vec![bid],
            seat: "cineradar".into(),
        }],
    })
}

#[tokio::main]
async fn main() {
    let app = Router::new()
        .route("/bid", post(handle_bid));
    
    axum::serve(
        tokio::net::TcpListener::bind("0.0.0.0:3000").await.unwrap(),
        app
    ).await.unwrap();
}
```

#### Partner Integrations

| Partner | Protocol | Priority | Status |
|---------|----------|----------|--------|
| Stickearn | REST API | High | Week 7 |
| Moving Walls | OpenRTB 2.6 | Medium | Week 7 |
| Vistar Media | OpenRTB 2.6 | Medium | Week 8 |

#### Deliverables

- [ ] Stickearn REST adapter
- [ ] OpenRTB 2.6 bid server (Rust/Go)
- [ ] Campaign creation API
- [ ] Win notification handling
- [ ] Performance reporting dashboard

---

### Week 8: Partnership Execution

**Focus:** Business development, not technical.

#### Technical Collateral

- [ ] Partner pitch deck with architecture diagrams
- [ ] API demo environment (sandbox)
- [ ] Revenue share calculator
- [ ] Integration timeline templates

---

# MARCH (Weeks 9-12)
## Studio Products: Analytics Portal

---

### Week 9: Multi-Tenant Studio Portal

**Objective:** White-label analytics portal for film studios.

#### Multi-Tenant Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Multi-Tenant SaaS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  disney.cineradar.id â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  warner.cineradar.id â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â–¶ Next.js 16 App        â”‚
â”‚  falcon.cineradar.id â”€â”€â”€â”€â”€â”€â”˜    (App Router)           â”‚
â”‚                                       â”‚                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚              â”‚        Middleware      â–¼               â”‚â”‚
â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚              â”‚  â”‚ getTenantFromSubdomain(request)  â”‚  â”‚â”‚
â”‚              â”‚  â”‚ applyBranding(tenant)            â”‚  â”‚â”‚
â”‚              â”‚  â”‚ filterData(tenant)               â”‚  â”‚â”‚
â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Clerk      â”‚    â”‚  PostgreSQL â”‚    â”‚  Branding   â”‚ â”‚
â”‚  â”‚  (Auth)     â”‚    â”‚  (Data)     â”‚    â”‚  (Config)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Framework | Next.js 16 (App Router) | SSR + API routes |
| Auth | Clerk | Multi-tenant auth |
| UI | Shadcn/ui + Tailwind | Component library |
| Charts | Recharts + D3.js | Visualizations |
| Export | React-PDF, pptxgenjs | Reports |

#### Deliverables

- [ ] Tenant provisioning system
- [ ] Custom branding per tenant (logo, colors)
- [ ] Role-based access control (RBAC)
- [ ] PowerPoint export with charts
- [ ] White-label responsive design

---

### Week 10: Release Timing Optimizer

**Objective:** Help studios pick optimal release dates.

#### Monte Carlo Simulation

```python
# release_optimizer.py
import numpy as np
from dataclasses import dataclass
from typing import List
import polars as pl

@dataclass
class ReleaseSimulation:
    mean_revenue: float
    p10: float  # 10th percentile (downside)
    p50: float  # Median
    p90: float  # 90th percentile (upside)
    competitor_risk: float
    recommendation: str

def simulate_release(
    movie_profile: dict,
    release_date: str,
    num_simulations: int = 10_000
) -> ReleaseSimulation:
    """
    Monte Carlo simulation for release date optimization
    """
    base_estimate = calculate_base_revenue(movie_profile)
    
    results = []
    for _ in range(num_simulations):
        # Random factors
        competitor_impact = np.random.normal(0, 0.15)  # Â±15% variance
        holiday_boost = get_holiday_multiplier(release_date)
        seasonal_factor = get_seasonality(release_date)
        marketing_variance = np.random.normal(1.0, 0.1)
        
        predicted_revenue = (
            base_estimate 
            * (1 + competitor_impact)
            * holiday_boost
            * seasonal_factor
            * marketing_variance
        )
        results.append(predicted_revenue)
    
    results = np.array(results)
    
    return ReleaseSimulation(
        mean_revenue=float(np.mean(results)),
        p10=float(np.percentile(results, 10)),
        p50=float(np.percentile(results, 50)),
        p90=float(np.percentile(results, 90)),
        competitor_risk=calculate_competitor_risk(release_date),
        recommendation=generate_recommendation(results)
    )
```

#### Deliverables

- [ ] Historical release performance analysis
- [ ] Calendar heatmap visualization
- [ ] What-if scenario simulator
- [ ] PDF recommendation report generator
- [ ] API for studio integrations

---

### Week 11: Competitive Intelligence

**Objective:** Track competitor movies and market share.

#### Data Pipeline

```python
# competitor_tracker.py
from playwright.async_api import async_playwright
from openai import OpenAI
import asyncio

async def scrape_box_office():
    """Scrape KDB and other box office sources"""
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        
        # Scrape KDB
        await page.goto("https://kdb.or.id/box-office")
        data = await page.evaluate("() => extractBoxOfficeData()")
        
        return data

def summarize_with_ai(news_articles: list) -> str:
    """Use GPT-4 to summarize competitor news"""
    client = OpenAI()
    
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{
            "role": "system",
            "content": "Summarize cinema industry news for executives."
        }, {
            "role": "user", 
            "content": f"Summarize: {news_articles}"
        }]
    )
    
    return response.choices[0].message.content
```

#### Deliverables

- [ ] Competitor movie tracker (screens, showtimes)
- [ ] Box office monitoring (daily/weekly)
- [ ] Alert system (Slack/Telegram/Email)
- [ ] Weekly digest automation
- [ ] Market share trend analysis

---

### Week 12: Enterprise Sales Execution

**Focus:** Sales tools and demos.

- [ ] ROI calculator web app
- [ ] Demo environment with realistic data
- [ ] Case study one-pagers
- [ ] Proposal generator

---

*[Continued in separate sections for April-June: Pre-Roll Marketplace, Geo-Targeting, Audience Segmentation, Dynamic Pricing, Event Analytics]*

---

# Development Principles

1. **Ship weekly:** Every week ends with a deployable artifact
2. **Test on production:** Real data, real users, fast feedback
3. **Iterate fast:** Week 2 fixes Week 1 bugs
4. **Document as you go:** Every API documented with OpenAPI
5. **Automate everything:** CI/CD from Day 1

---

## Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | Dec 2025 | CineRadar Team | Initial H1 detailed spec |
